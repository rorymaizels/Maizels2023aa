{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Running UniTVelo 0.2.5.2)\n",
      "2023-01-23 11:07:00\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ann\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.sparse import issparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import scvelo as scv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from unitvelo.eval_utils import cross_boundary_correctness, inner_cluster_coh\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import unitvelo as utv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitvelo_pipeline(adata0, name):\n",
    "    adata = adata0.copy()\n",
    "    dataset = f'../data/benchmarking_data/{name}.h5ad'\n",
    "    label='leiden'\n",
    "    velo_config = utv.config.Configuration()\n",
    "    velo_config.R2_ADJUST = True\n",
    "    velo_config.IROOT = None\n",
    "    velo_config.FIT_OPTION = '1'\n",
    "    velo_config.AGENES_R2 = 1\n",
    "    velo_config.MIN_SHARED_COUNTS = 0\n",
    "    velo_config.N_TOP_GENES = len(adata0.var_names)\n",
    "    velo_config.N_PCs = 50\n",
    "    velo_config.USE_RAW = False\n",
    "    velo_config.RESCALE_DATA = True\n",
    "    \n",
    "    adata = utv.run_model(dataset, label, config_file=velo_config)\n",
    "    \n",
    "    V = adata.layers['velocity']\n",
    "    V = V.A if issparse(V) else V\n",
    "    V = np.nan_to_num(V, nan=0, neginf=0, posinf=0)\n",
    "    \n",
    "    return V\n",
    "\n",
    "def unitvelo_pipeline_without_smoothing(adata0, name):\n",
    "    adata = adata0.copy()\n",
    "    dataset = f'../data/benchmarking_data/{name}.h5ad'\n",
    "    label='leiden'\n",
    "    velo_config = utv.config.Configuration()\n",
    "    velo_config.R2_ADJUST = True\n",
    "    velo_config.IROOT = None\n",
    "    velo_config.FIT_OPTION = '1'\n",
    "    velo_config.AGENES_R2 = 1\n",
    "    velo_config.MIN_SHARED_COUNTS = 0\n",
    "    velo_config.N_TOP_GENES = len(adata0.var_names)\n",
    "    velo_config.N_PCs = 50\n",
    "    velo_config.USE_RAW = True # only difference\n",
    "    velo_config.RESCALE_DATA = True\n",
    "    \n",
    "    adata = utv.run_model(dataset, label, config_file=velo_config)\n",
    "    \n",
    "    V = adata.layers['velocity']\n",
    "    V = V.A if issparse(V) else V\n",
    "    V = np.nan_to_num(V, nan=0, neginf=0, posinf=0)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions used in preparing data for benchmarking\n",
    "\n",
    "def project_to_pca(adata):\n",
    "    X = adata.layers['total']\n",
    "    V = adata.layers['velocity']\n",
    "\n",
    "    X = np.array(X.A if issparse(X) else X)\n",
    "    V = np.array(V.A if issparse(V) else V)\n",
    "    V = np.nan_to_num(V, nan=0, neginf=0, posinf=0)\n",
    "    Y = np.clip(X + V, 0, 1000)\n",
    "\n",
    "\n",
    "    Xlog = np.log1p(X)\n",
    "    pca = PCA()\n",
    "    Xpca = pca.fit_transform(Xlog)\n",
    "\n",
    "    Ylog = np.log1p(Y)\n",
    "    Ypca = pca.transform(Ylog)\n",
    "    V = Ypca - Xpca\n",
    "    return V\n",
    "\n",
    "def prepare_for_test(\n",
    "    adata,\n",
    "    name,\n",
    "    func,\n",
    "    ndims=50,\n",
    "    pt=True,\n",
    "):\n",
    "    x_pca = adata.obsm['X_pca']\n",
    "    velocity = func(adata, name)\n",
    "\n",
    "    test = ann.AnnData(X=adata.X, obs=adata.obs, var=adata.var,\n",
    "                       layers={'total':adata.layers['total'],\n",
    "                               'velocity':velocity})\n",
    "\n",
    "    test.obsm['X_pca'] = x_pca[:,:ndims]\n",
    "    test.obsm['cellrank_baseline'] = adata.obsm['velocity_cr_pca'][:,:ndims]\n",
    "    if pt:\n",
    "        test.obsm['pseudotime_baseline'] = adata.obsm['velocity_pst'][:,:ndims]\n",
    "    else:\n",
    "        ## this is a lazy implementation, will create meaningless comparison\n",
    "        ## but it will never get saved\n",
    "        ## this is just for the maxi dataset that we don't have a good\n",
    "        ## pseudotime trajectory skeleton for.\n",
    "        test.obsm['pseudotime_baseline'] = np.zeros_like(test.obsm['cellrank_baseline'])\n",
    "        \n",
    "    test.obsm['velocity_pca'] = project_to_pca(test)[:,:ndims]\n",
    "    \n",
    "    scv.pp.neighbors(test)\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the object that will contain the data and data-specific parameters for benchmarking\n",
    "\n",
    "class BenchMarkingData:\n",
    "    def __init__(self, name, func, pt=True):\n",
    "        self.name = name\n",
    "        adata = sc.read_h5ad(f'../data/benchmarking_data/{name}.h5ad')\n",
    "\n",
    "        self.adata = prepare_for_test(\n",
    "            adata,\n",
    "            name,\n",
    "            func,\n",
    "            pt=pt\n",
    "        )\n",
    "        \n",
    "        self.cluster_edges()\n",
    "        \n",
    "    def cluster_edges(self):\n",
    "        if \"mini_V3\" in self.name:\n",
    "            self.obs = 'leiden'\n",
    "            self.cluster_edges = [\n",
    "                ('5','14'),\n",
    "                ('14','8'),\n",
    "                ('8','21')\n",
    "            ]\n",
    "        elif \"mini_MN\" in self.name:\n",
    "            self.obs = 'leiden'\n",
    "            self.cluster_edges = [\n",
    "                ('16','15'),\n",
    "                ('20','23'),\n",
    "                ('13','18')\n",
    "            ]\n",
    "        elif \"mini_MD\" in self.name:\n",
    "            self.obs = 'leiden'\n",
    "            self.cluster_edges = [\n",
    "                ('9','12'),\n",
    "                ('25','4'),\n",
    "                ('4','6'),\n",
    "                ('6','22')\n",
    "            ]\n",
    "        elif \"midi_NM\" in self.name:\n",
    "            self.obs = 'cell_annotation'\n",
    "            self.cluster_edges = [\n",
    "                ('Early_Neural','Neural'),\n",
    "                ('NMP','Early_Neural'),\n",
    "                ('NMP','Mesoderm')\n",
    "            ]\n",
    "        elif 'midi_Ne' in self.name:\n",
    "            self.obs = 'cell_annotation'\n",
    "            self.cluster_edges = [\n",
    "                ('Neural','pMN'),\n",
    "                ('pMN','MN'),\n",
    "                ('pMN','p3'),\n",
    "                ('p3','V3')\n",
    "            ]\n",
    "        elif 'maxi' in self.name:\n",
    "            self.obs = 'cell_annotation'\n",
    "            self.cluster_edges = [\n",
    "                ('Early_Neural','Neural'),\n",
    "                ('NMP','Early_Neural'),\n",
    "                ('NMP','Mesoderm'),\n",
    "                ('Neural','pMN'),\n",
    "                ('pMN','MN'),\n",
    "                ('pMN','p3'),\n",
    "                ('p3','V3')\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the benchmarking functions\n",
    "### cross_boundary_correctness and inner_cluster_coh use implementation from unitvelo\n",
    "### web: https://unitvelo.readthedocs.io/en/latest/\n",
    "### paper: https://www.nature.com/articles/s41467-022-34188-7\n",
    "\n",
    "def baseline_scores(\n",
    "    adata\n",
    "):\n",
    "    X = adata.obsm['velocity_pca']\n",
    "    Y1 = adata.obsm['cellrank_baseline']\n",
    "    Y2 = adata.obsm['pseudotime_baseline']\n",
    "    cr_scores = np.diagonal(cosine_similarity(X, Y1))\n",
    "    pt_scores = np.diagonal(cosine_similarity(X, Y2))\n",
    "    return cr_scores, pt_scores\n",
    "\n",
    "def run_tests(bm):\n",
    "    cbd = cross_boundary_correctness(\n",
    "        bm.adata,\n",
    "        k_cluster=bm.obs,\n",
    "        k_velocity='velocity',\n",
    "        x_emb='X_pca',\n",
    "        cluster_edges=bm.cluster_edges\n",
    "    )[1]\n",
    "\n",
    "    icc = inner_cluster_coh(\n",
    "        bm.adata,\n",
    "        k_cluster=bm.obs,\n",
    "        k_velocity='velocity',\n",
    "    )[1]\n",
    "    \n",
    "    crs, pts = baseline_scores(bm.adata)\n",
    "    \n",
    "    return cbd, icc, crs, pts\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_benchmark(\n",
    "    pipeline_name,\n",
    "    velocity_pipeline, \n",
    "    output_folder\n",
    "):\n",
    "    dataset = ['splicing_mini_V3', 'splicing_mini_MN', 'splicing_mini_MD',\n",
    "               'splicing_midi_NM', 'splicing_midi_Ne', 'splicing_maxi']\n",
    "    \n",
    "    for ds in tqdm(dataset):  \n",
    "        bm_data = BenchMarkingData(ds, velocity_pipeline, pt=(ds!='splicing_maxi'))\n",
    "        print(ds)\n",
    "        cbd, icc, crs, pts = run_tests(bm_data)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CBD.npy', cbd)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_ICC.npy', icc)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CRS.npy', crs)\n",
    "        if ds!='splicing_maxi':\n",
    "            np.save(f'{output_folder}/{ds}_{pipeline_name}_PTS.npy', pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform_benchmark(\n",
    "#     pipeline_name='UniTVelo',\n",
    "#     velocity_pipeline=unitvelo_pipeline, \n",
    "#     output_folder='../output_data/'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_benchmark(\n",
    "    pipeline_name,\n",
    "    velocity_pipeline, \n",
    "    output_folder\n",
    "):\n",
    "    dataset = ['splicing_maxi']\n",
    "    \n",
    "    for ds in tqdm(dataset):  \n",
    "        bm_data = BenchMarkingData(ds, velocity_pipeline, pt=(ds!='splicing_maxi'))\n",
    "        print(ds)\n",
    "        cbd, icc, crs, pts = run_tests(bm_data)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CBD.npy', cbd)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_ICC.npy', icc)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CRS.npy', crs)\n",
    "        if ds!='splicing_maxi':\n",
    "            np.save(f'{output_folder}/{ds}_{pipeline_name}_PTS.npy', pts)\n",
    "            \n",
    "    clear_output()\n",
    "    print('all done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done.\n"
     ]
    }
   ],
   "source": [
    "perform_benchmark(\n",
    "    pipeline_name='UniTVelo_RAW',\n",
    "    velocity_pipeline=unitvelo_pipeline_without_smoothing, \n",
    "    output_folder='../output_data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velvet_dev",
   "language": "python",
   "name": "velvet_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
