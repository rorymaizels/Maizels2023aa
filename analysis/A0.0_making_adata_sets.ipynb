{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6eb4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import velvet as vt\n",
    "\n",
    "# general packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# velocity packages\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import anndata as ann\n",
    "\n",
    "# plotting packages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# color palette object\n",
    "from colors import colorpalette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087131d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#script-specific imports\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758ee517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_adatas(\n",
    "    home, \n",
    "    pos_pattern='MAI',\n",
    "    neg_pattern='tmp',\n",
    "    method='count'):\n",
    "    \"\"\"\n",
    "    load adatas from outputs of dynast.\n",
    "    This function is specifically built for the directory structure\n",
    "    of our data.\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "    samples = [f for f in os.listdir(home) if pos_pattern in f]\n",
    "    samples = [f for f in samples if neg_pattern not in f]\n",
    "    adata_list = []\n",
    "    for sample in tqdm(samples):\n",
    "        try:\n",
    "            adata = sc.read_h5ad(home+sample+f'/{method}/adata.h5ad')\n",
    "            adata.obs.index = ['_'.join((sample,a)) for a in adata.obs.index]\n",
    "            adata.obs['sample'] = sample\n",
    "            adata.var['ID'] = adata.var.index\n",
    "            adata.var = adata.var.set_index('gene_name')\n",
    "            try:\n",
    "                adata = adata[:,[a!='' for a in adata.var_names]]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            adata.var.index = adata.var.index.astype(\"string\")\n",
    "            adata.var_names_make_unique()\n",
    "            adata.obs_names_make_unique()\n",
    "            adata.strings_to_categoricals()\n",
    "            adata_list.append(adata)\n",
    "            clear_output(wait=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{sample} not found.\")\n",
    "    total_adata = ann.concat(adata_list, join='outer', fill_value=0, axis=0)\n",
    "    return total_adata\n",
    "\n",
    "def load_data(path, timepoints, method='estimate', cutoff=1000):\n",
    "    \"\"\"\n",
    "    aggregate across the different conditions for a replicate\n",
    "    \"\"\"\n",
    "    adatas = []\n",
    "    for tp in timepoints:\n",
    "        print(path+tp+'/')\n",
    "        adata = aggregate_adatas(path+tp+'/', method=method)\n",
    "        adata.obs['timepoint'] = tp\n",
    "        adatas.append(adata)\n",
    "    adata = ann.concat(adatas)\n",
    "    adata = adata[adata.layers['total'].sum(1)>cutoff]\n",
    "    return adata\n",
    "\n",
    "def save_file(adata, name, X='total'):\n",
    "    \"\"\"\n",
    "    there's an issue with string formatting, which this fixes.\n",
    "    \"\"\"\n",
    "    coldict = {}\n",
    "    for col in adata.obs.columns:\n",
    "        coldict[col] = [a for a in adata.obs[col]]\n",
    "    new_obs = pd.DataFrame(coldict, index=list(adata.obs.index.values))\n",
    "\n",
    "    coldict = {}\n",
    "    for col in adata.var.columns:\n",
    "        coldict[col] = [a for a in adata.var[col]]\n",
    "    new_var = pd.DataFrame(coldict, index=list(adata.var.index.values))\n",
    "    \n",
    "    adata = ann.AnnData(X=adata.layers[X].copy(),\n",
    "                         obs=new_obs,\n",
    "                         var=new_var,\n",
    "                         layers=adata.layers.copy())\n",
    "    \n",
    "    adata.write(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068224e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [01:05<00:00,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "home = '/camp/lab/briscoej/working/Rory/transcriptomics/sciFATE_data/experiments/'\n",
    "tp1 = ['D3','D4','D5','D6','D7','D8']\n",
    "tp2 = ['05h','10h','15h','20h']\n",
    "\n",
    "r1 = load_data(\n",
    "    path=home+'/E1.1/data/',\n",
    "    timepoints=tp1\n",
    ")\n",
    "\n",
    "r2 = load_data(\n",
    "    path=home+'/E2.1/data/',\n",
    "    timepoints=tp1\n",
    ")\n",
    "\n",
    "r3 = load_data(\n",
    "    path=home+'/E3.1/data/',\n",
    "    timepoints=tp1\n",
    ")\n",
    "\n",
    "r4 = load_data(\n",
    "    path=home+'/EX1/data/',\n",
    "    timepoints=tp2\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41707c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ann.concat([r1,r2,r3,r4])\n",
    "adata.obs['rep'] = ['r1']*r1.shape[0] + ['r2']*r2.shape[0] + ['r3']*r3.shape[0] + ['r4']*r4.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b05ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['new_estimated'] = adata.layers['labeled_TC_est'].copy()\n",
    "adata.layers['new'] = adata.layers['labeled_TC'].copy()\n",
    "adata.layers['old_estimated'] = adata.layers['unlabeled_TC_est'].copy()\n",
    "adata.layers['old'] = adata.layers['unlabeled_TC'].copy()\n",
    "\n",
    "adata2 = adata.copy()\n",
    "for layer in adata.layers:\n",
    "    if layer in ['total','new','old']:\n",
    "        adata2.layers[layer] = adata2.layers[layer].astype('float32')\n",
    "    else:\n",
    "        del adata2.layers[layer]\n",
    "        \n",
    "adata3 = adata.copy()\n",
    "for layer in adata.layers:\n",
    "    if layer in ['total','new_estimated','old_estimated']:\n",
    "        adata3.layers[layer] = adata3.layers[layer].astype('float32')\n",
    "    else:\n",
    "        del adata3.layers[layer]\n",
    "        \n",
    "adata4 = adata.copy()\n",
    "for layer in adata.layers:\n",
    "    if layer in ['spliced','unspliced']:\n",
    "        adata4.layers[layer] = adata4.layers[layer].astype('float32')\n",
    "    else:\n",
    "        del adata4.layers[layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90811a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(adata2, '../data/adata_unprocessed.h5ad', X='total')\n",
    "save_file(adata3, '../data/adata_unprocessed_estimate.h5ad', X='total')\n",
    "save_file(adata4, '../data/adata_unprocessed_splicing.h5ad', X='spliced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuckl yo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46074e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velvet_env1",
   "language": "python",
   "name": "velvet_env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
