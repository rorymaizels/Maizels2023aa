/usr/bin/python/camp/apps/eb/software/Anaconda2/2019.03/condabin/condaMon Jan 15 21:08:54 2024       +---------------------------------------------------------------------------------------+| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     ||-----------------------------------------+----------------------+----------------------+| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. ||                                         |                      |               MIG M. ||=========================================+======================+======================||   0  Tesla V100-SXM2-32GB           On  | 00000000:1C:00.0 Off |                    0 || N/A   31C    P0              42W / 300W |      0MiB / 32768MiB |      0%      Default ||                                         |                      |                  N/A |+-----------------------------------------+----------------------+----------------------+                                                                                         +---------------------------------------------------------------------------------------+| Processes:                                                                            ||  GPU   GI   CI        PID   Type   Process name                            GPU Memory ||        ID   ID                                                             Usage      ||=======================================================================================||  No running processes found                                                           |+---------------------------------------------------------------------------------------+nvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2020 NVIDIA CorporationBuilt on Mon_Oct_12_20:09:46_PDT_2020Cuda compilation tools, release 11.1, V11.1.105Build cuda_11.1.TC455_06.29190527_0Global seed set to 0/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.  new_rank_zero_deprecation(/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.  return new_rank_zero_deprecation(*args, **kwargs)  0%|          | 0/6 [00:00<?, ?it/s]  0%|          | 0/6 [13:06<?, ?it/s]Skip filtering by dispersion since number of variables are less than `n_top_genes`.using all genescomputing neighbors    finished (0:00:09) --> added     'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)computing moments based on connectivities    finished (0:00:00) --> added     'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)Warning, folder already exists. This may overwrite a previous fit.1275 velocity genes usedepoch 0, full loss 177.851, val loss 40.191, recon MSE 0.132, traj MSE 0.022, reg loss -1.979epoch 1, full loss 82.081, val loss 22.818, recon MSE 0.117, traj MSE 0.012, reg loss -3.165epoch 2, full loss 63.741, val loss 10.254, recon MSE 0.094, traj MSE 0.006, reg loss -3.743epoch 3, full loss 59.060, val loss -2.125, recon MSE 0.060, traj MSE 0.004, reg loss -4.051epoch 4, full loss 60.214, val loss -14.420, recon MSE 0.038, traj MSE 0.004, reg loss -4.091epoch 5, full loss 69.685, val loss -26.201, recon MSE 0.021, traj MSE 0.004, reg loss -4.252epoch 6, full loss 86.799, val loss -37.214, recon MSE 0.014, traj MSE 0.004, reg loss -4.288epoch 7, full loss 105.530, val loss -47.029, recon MSE 0.011, traj MSE 0.004, reg loss -4.212epoch 8, full loss 127.723, val loss -55.609, recon MSE 0.010, traj MSE 0.004, reg loss -4.266epoch 9, full loss 150.844, val loss -62.899, recon MSE 0.008, traj MSE 0.003, reg loss -3.769epoch 10, full loss 164.888, val loss -67.999, recon MSE 0.007, traj MSE 0.003, reg loss -3.465epoch 11, full loss 174.083, val loss -70.862, recon MSE 0.006, traj MSE 0.003, reg loss -3.579epoch 12, full loss 159.801, val loss -70.738, recon MSE 0.005, traj MSE 0.003, reg loss -3.152epoch 13, full loss 155.776, val loss -70.812, recon MSE 0.005, traj MSE 0.003, reg loss -3.371epoch 14, full loss 156.564, val loss -68.469, recon MSE 0.004, traj MSE 0.003, reg loss -3.527epoch 15, full loss 124.268, val loss -63.987, recon MSE 0.004, traj MSE 0.003, reg loss -3.682epoch 16, full loss 117.197, val loss -61.328, recon MSE 0.004, traj MSE 0.003, reg loss -3.690epoch 17, full loss 96.881, val loss -56.445, recon MSE 0.004, traj MSE 0.003, reg loss -3.687epoch 18, full loss 86.932, val loss -51.775, recon MSE 0.004, traj MSE 0.003, reg loss -3.714epoch 19, full loss 67.764, val loss -46.921, recon MSE 0.004, traj MSE 0.003, reg loss -3.765epoch 20, full loss 58.651, val loss -41.242, recon MSE 0.003, traj MSE 0.003, reg loss -3.568epoch 21, full loss 48.203, val loss -36.765, recon MSE 0.003, traj MSE 0.003, reg loss -3.715epoch 22, full loss 41.205, val loss -31.238, recon MSE 0.003, traj MSE 0.003, reg loss -3.594epoch 23, full loss 33.301, val loss -25.968, recon MSE 0.003, traj MSE 0.003, reg loss -3.615epoch 24, full loss 26.523, val loss -20.912, recon MSE 0.003, traj MSE 0.003, reg loss -3.564Epoch 00025: reducing learning rate of group 0 to 7.5000e-03.epoch 25, full loss 22.282, val loss -16.295, recon MSE 0.003, traj MSE 0.003, reg loss -3.787epoch 26, full loss 19.819, val loss -16.424, recon MSE 0.003, traj MSE 0.003, reg loss -3.654epoch 27, full loss 18.552, val loss -16.072, recon MSE 0.003, traj MSE 0.003, reg loss -3.684epoch 28, full loss 14.980, val loss -16.361, recon MSE 0.003, traj MSE 0.003, reg loss -3.700epoch 29, full loss 13.156, val loss -16.467, recon MSE 0.003, traj MSE 0.003, reg loss -3.658epoch 30, full loss 10.931, val loss -16.742, recon MSE 0.003, traj MSE 0.003, reg loss -3.758epoch 31, full loss 13.228, val loss -16.429, recon MSE 0.003, traj MSE 0.003, reg loss -3.688epoch 32, full loss 9.330, val loss -16.851, recon MSE 0.003, traj MSE 0.003, reg loss -3.686epoch 33, full loss 8.164, val loss -16.751, recon MSE 0.003, traj MSE 0.003, reg loss -3.616epoch 34, full loss 7.330, val loss -16.365, recon MSE 0.003, traj MSE 0.003, reg loss -3.723epoch 35, full loss 5.901, val loss -16.654, recon MSE 0.003, traj MSE 0.003, reg loss -3.662epoch 36, full loss 3.114, val loss -16.536, recon MSE 0.003, traj MSE 0.003, reg loss -3.614Epoch 00037: reducing learning rate of group 0 to 5.6250e-03.epoch 37, full loss 5.085, val loss -16.734, recon MSE 0.003, traj MSE 0.003, reg loss -3.767epoch 38, full loss 5.119, val loss -16.901, recon MSE 0.003, traj MSE 0.003, reg loss -3.742epoch 39, full loss 2.914, val loss -16.930, recon MSE 0.003, traj MSE 0.003, reg loss -3.725epoch 40, full loss 3.821, val loss -17.275, recon MSE 0.003, traj MSE 0.003, reg loss -3.767epoch 41, full loss 3.648, val loss -16.657, recon MSE 0.003, traj MSE 0.003, reg loss -3.769epoch 42, full loss 3.000, val loss -16.913, recon MSE 0.003, traj MSE 0.003, reg loss -3.767Epoch 00043: reducing learning rate of group 0 to 4.2188e-03.epoch 43, full loss 2.458, val loss -17.048, recon MSE 0.003, traj MSE 0.003, reg loss -3.938epoch 44, full loss 3.363, val loss -17.070, recon MSE 0.003, traj MSE 0.003, reg loss -3.871epoch 45, full loss 2.533, val loss -16.985, recon MSE 0.003, traj MSE 0.003, reg loss -3.883epoch 46, full loss 1.202, val loss -17.219, recon MSE 0.003, traj MSE 0.003, reg loss -3.843epoch 47, full loss 2.182, val loss -17.333, recon MSE 0.003, traj MSE 0.003, reg loss -3.894epoch 48, full loss 2.124, val loss -17.361, recon MSE 0.003, traj MSE 0.003, reg loss -2.419Epoch 00049: reducing learning rate of group 0 to 3.1641e-03.epoch 49, full loss 2.061, val loss -17.428, recon MSE 0.003, traj MSE 0.003, reg loss -2.610Loading best model at 49 epochs.Traceback (most recent call last):  File "/nemo/lab/briscoej/home/users/maizelr/transcriptomics/SVM23/analysis/A2.2_benchmarking/B10_latentvelo_benchmarking.py", line 123, in <module>    bench_func(  File "/nemo/lab/briscoej/home/users/maizelr/transcriptomics/SVM23/analysis/A2.2_benchmarking/benchmarking_functions.py", line 323, in perform_benchmark_splicing    bm_data = BenchMarkingData(ds, velocity_pipeline, pt=(ds!='splicing_maxi'))  File "/nemo/lab/briscoej/home/users/maizelr/transcriptomics/SVM23/analysis/A2.2_benchmarking/benchmarking_functions.py", line 38, in __init__    self.adata = prepare_for_test(  File "/nemo/lab/briscoej/home/users/maizelr/transcriptomics/SVM23/analysis/A2.2_benchmarking/benchmarking_functions.py", line 218, in prepare_for_test    velocity = func(adata, name)  File "/nemo/lab/briscoej/home/users/maizelr/transcriptomics/SVM23/analysis/A2.2_benchmarking/B10_latentvelo_benchmarking.py", line 105, in latentvelo_pipeline_without_smoothing    os.system('rm -r delete')NameError: name 'os' is not defined