{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e59d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import velvet as vt\n",
    "\n",
    "# general packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# velocity packages\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import anndata as ann\n",
    "\n",
    "# plotting packages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# color palette object\n",
    "from colors import colorpalette as colpal\n",
    "\n",
    "# we implement unitvelo's evaluation \n",
    "# originally from https://github.com/StatBiomed/UniTVelo/blob/main/unitvelo/eval_utils.py\n",
    "# paper: https://www.nature.com/articles/s41467-022-34188-7\n",
    "# authors: Mingze Gao, Chen Qiao & Yuanhua Huang \n",
    "\n",
    "from eval_functions import unitvelo_cross_boundary_correctness as cross_boundary_correctness\n",
    "from  eval_functions import unitvelo_inner_cluster_coh as inner_cluster_coh\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# the object that will contain the data and data-specific parameters for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b6ce4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_specific_benchmark(output_folder, pipeline, pipeline_name):\n",
    "    gene_results = {\n",
    "        'mini_MN':[\n",
    "            ['leiden','4','Olig2','-'],\n",
    "            ['leiden','4','Tubb3','+'],\n",
    "            ['leiden','2','Neurog2','+'],\n",
    "            ['leiden','3','Isl2','+'],\n",
    "        ],\n",
    "        'mini_V3':[\n",
    "            ['leiden','1','Sim1','+'],\n",
    "            ['leiden','1','Sox2','-'],\n",
    "            ['leiden','3','Tubb3','+'],\n",
    "            ['leiden','1','Map2','+'],\n",
    "        ],\n",
    "        'mini_MD':[\n",
    "            ['leiden','3','Sox2','-'],\n",
    "            ['leiden','3','Nkx1-2','-'],\n",
    "            ['leiden','3','T','-'],\n",
    "            ['leiden','2','Meox1','+'],\n",
    "        ],\n",
    "        'midi_NM':[\n",
    "            ['cell_annotation','Neural','Olig2','+'],\n",
    "            ['cell_annotation','Neural','T','-'],\n",
    "            ['cell_annotation','Mesoderm','Meox1','+'],\n",
    "            ['cell_annotation','Early_Neural','Irx3','+'],\n",
    "        ],\n",
    "        'midi_Ne':[\n",
    "            ['cell_annotation','Neural','Olig2','+'],\n",
    "            ['cell_annotation','FP','Shh','+'],\n",
    "            ['cell_annotation','P3','Nkx2-2','+'],\n",
    "            ['cell_annotation','pMN','Irx3','-'],\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for name, settings in gene_results.items():\n",
    "        print(f\"GENE SCORE: {name}\")\n",
    "        adata = sc.read_h5ad(f'../../data/benchmarking/{name}.h5ad')\n",
    "        adata.layers['velocity'] = pipeline(adata, name)\n",
    "\n",
    "        for seti in settings:\n",
    "            sub = adata[adata.obs[seti[0]]==seti[1]]\n",
    "            vel = sub[:,seti[2]].layers['velocity'].flatten()\n",
    "            if seti[3]=='-':\n",
    "                score = np.mean(vel<0)\n",
    "            elif seti[3]=='+':\n",
    "                score = np.mean(vel>0)\n",
    "            scores.append(score)\n",
    "           \n",
    "    scores = np.array(scores)\n",
    "    np.save(f'{output_folder}/{pipeline_name}_gene_specific_scores.npy', scores)\n",
    "\n",
    "def consistency_benchmark(output_folder, pipeline, pipeline_name):\n",
    "    print('1')\n",
    "    consistency_results = {\n",
    "        'Neural':[\n",
    "            ['midi_NM','midi_Ne'],\n",
    "            ['Olig2','Irx3','Sema3e','Nkx1-2']\n",
    "        ],\n",
    "        'pMN':[\n",
    "            ['mini_MN','midi_Ne'],\n",
    "            ['Olig2','Neurog2','Mnx1','Isl2']\n",
    "        ],\n",
    "        'MN':[\n",
    "            ['mini_MN','midi_Ne'],\n",
    "            ['Tubb3','Neurog2','Map2','Olig2']\n",
    "        ],\n",
    "        'V3':[\n",
    "            ['mini_V3','midi_Ne'],\n",
    "            ['Tubb3','Sim1','Map2','Stmn2']\n",
    "        ],\n",
    "        'p3':[\n",
    "            ['mini_V3','midi_Ne'],\n",
    "            ['Sim1','Nfia','Sox9','Nfib']\n",
    "        ],\n",
    "        'Mesoderm':[\n",
    "            ['mini_MD','midi_NM'],\n",
    "            ['Meox1','T','Rspo3','Cyp26a1']\n",
    "        ],\n",
    "        'NMP':[\n",
    "            ['midi_NM','maxi'],\n",
    "            ['Rspo3','T','Sema3e','Fgf8']\n",
    "        ],\n",
    "        'FP':[\n",
    "            ['midi_Ne','maxi'],\n",
    "            ['Shh','Arx','Olig2','Foxa2']\n",
    "        ],\n",
    "        'Early_Neural':[\n",
    "            ['midi_NM','maxi'],\n",
    "            ['Nkx1-2','Irx3','Sema3e','Olig2']\n",
    "        ]\n",
    "    }\n",
    "    scores = []\n",
    "    for cell, settings in consistency_results.items():\n",
    "        print(f\"CONSISTENCY: {cell}\")\n",
    "        fir = sc.read_h5ad(f'../../data/benchmarking/{settings[0][0]}.h5ad')\n",
    "        sec = sc.read_h5ad(f'../../data/benchmarking/{settings[0][1]}.h5ad')\n",
    "\n",
    "        fir.layers['velocity'] = pipeline(fir, pipeline_name)\n",
    "        sec.layers['velocity'] = pipeline(sec, pipeline_name)\n",
    "\n",
    "        fir_sub = fir[fir.obs.cell_annotation==cell]\n",
    "        sec_sub = sec[sec.obs.cell_annotation==cell]\n",
    "        shared_cells = list(set(fir_sub.obs_names).intersection(sec_sub.obs_names))\n",
    "        fir_sub = fir_sub[shared_cells]\n",
    "        sec_sub = sec_sub[shared_cells]\n",
    "        \n",
    "        print(settings[1])\n",
    "        \n",
    "        for gene in settings[1]:\n",
    "            proceed = True\n",
    "            print('proceed: ', proceed)\n",
    "#             try:\n",
    "            firvel = np.array(fir_sub[:,gene].layers['velocity']).flatten()\n",
    "            print('t1')\n",
    "#             except:\n",
    "#                 print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][0]}!\")\n",
    "#                 proceed = False\n",
    "#                 print('e1')\n",
    "#             try:\n",
    "            secvel = np.array(sec_sub[:,gene].layers['velocity']).flatten()\n",
    "            print('t2')\n",
    "#             except:\n",
    "#                 print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][1]}!\")\n",
    "#                 proceed = False\n",
    "#                 print('e2')\n",
    "            if proceed:\n",
    "                print(\"Score for ({cell}, {settings[1]}, {settings[0][0]},{settings[0][1]})\")\n",
    "                print(np.corrcoef(firvel, secvel)[0,1])\n",
    "                scores.append(np.corrcoef(firvel, secvel)[0,1])\n",
    "\n",
    "    scores = np.array(scores)\n",
    "#     np.save(f'{output_folder}/{pipeline_name}_consistency_scores.npy', scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d63eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_specific_benchmark_splicing(output_folder, pipeline, pipeline_name):\n",
    "    gene_results = {\n",
    "        'splicing_mini_MN':[\n",
    "            ['leiden','4','Olig2','-'],\n",
    "            ['leiden','4','Tubb3','+'],\n",
    "            ['leiden','2','Neurog2','+'],\n",
    "            ['leiden','3','Isl2','+'],\n",
    "        ],\n",
    "        'splicing_mini_V3':[\n",
    "            ['leiden','1','Sim1','+'],\n",
    "            ['leiden','1','Sox2','-'],\n",
    "            ['leiden','3','Tubb3','+'],\n",
    "            ['leiden','1','Map2','+'],\n",
    "        ],\n",
    "        'splicing_mini_MD':[\n",
    "            ['leiden','3','Sox2','-'],\n",
    "            ['leiden','3','Nkx1-2','-'],\n",
    "            ['leiden','3','T','-'],\n",
    "            ['leiden','2','Meox1','+'],\n",
    "        ],\n",
    "        'splicing_midi_NM':[\n",
    "            ['cell_annotation','Neural','Olig2','+'],\n",
    "            ['cell_annotation','Neural','T','-'],\n",
    "            ['cell_annotation','Mesoderm','Meox1','+'],\n",
    "            ['cell_annotation','Early_Neural','Irx3','+'],\n",
    "        ],\n",
    "        'splicing_midi_Ne':[\n",
    "            ['cell_annotation','Neural','Olig2','+'],\n",
    "            ['cell_annotation','FP','Shh','+'],\n",
    "            ['cell_annotation','P3','Nkx2-2','+'],\n",
    "            ['cell_annotation','pMN','Irx3','-'],\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for name, settings in gene_results.items():\n",
    "        print(f\"GENE SCORE: {name}\")\n",
    "        adata = sc.read_h5ad(f'../../data/benchmarking/{name}.h5ad')\n",
    "        adata.layers['velocity'] = pipeline(adata, name)\n",
    "\n",
    "        for seti in settings:\n",
    "            sub = adata[adata.obs[seti[0]]==seti[1]]\n",
    "            vel = sub[:,seti[2]].layers['velocity'].flatten()\n",
    "            if seti[3]=='-':\n",
    "                score = np.mean(vel<0)\n",
    "            elif seti[3]=='+':\n",
    "                score = np.mean(vel>0)\n",
    "            scores.append(score)\n",
    "           \n",
    "    scores = np.array(scores)\n",
    "    np.save(f'{output_folder}/{pipeline_name}_gene_specific_scores.npy', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37df16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency_benchmark_splicing(output_folder, pipeline, pipeline_name):\n",
    "    consistency_results = {\n",
    "        'Neural':[\n",
    "            ['splicing_midi_NM','splicing_midi_Ne'],\n",
    "            ['Olig2','Irx3','Sema3e','Nkx1-2']\n",
    "        ],\n",
    "        'pMN':[\n",
    "            ['splicing_mini_MN','splicing_midi_Ne'],\n",
    "            ['Olig2','Neurog2','Mnx1','Isl2']\n",
    "        ],\n",
    "        'MN':[\n",
    "            ['splicing_mini_MN','splicing_midi_Ne'],\n",
    "            ['Tubb3','Neurog2','Map2','Olig2']\n",
    "        ],\n",
    "        'V3':[\n",
    "            ['splicing_mini_V3','splicing_midi_Ne'],\n",
    "            ['Tubb3','Sim1','Map2','Stmn2']\n",
    "        ],\n",
    "        'p3':[\n",
    "            ['splicing_mini_V3','splicing_midi_Ne'],\n",
    "            ['Sim1','Nfia','Sox9','Nfib']\n",
    "        ],\n",
    "        'Mesoderm':[\n",
    "            ['splicing_mini_MD','splicing_midi_NM'],\n",
    "            ['Meox1','T','Rspo3','Cyp26a1']\n",
    "        ],\n",
    "        'NMP':[\n",
    "            ['splicing_midi_NM','splicing_maxi'],\n",
    "            ['Rspo3','T','Sema3e','Fgf8']\n",
    "        ],\n",
    "        'FP':[\n",
    "            ['splicing_midi_Ne','splicing_maxi'],\n",
    "            ['Shh','Arx','Olig2','Foxa2']\n",
    "        ],\n",
    "        'Early_Neural':[\n",
    "            ['splicing_midi_NM','splicing_maxi'],\n",
    "            ['Nkx1-2','Irx3','Sema3e','Olig2']\n",
    "        ]\n",
    "    }\n",
    "    scores = []\n",
    "    for cell, settings in consistency_results.items():\n",
    "        print(f\"CONSISTENCY: {cell}\")\n",
    "        fir = sc.read_h5ad(f'../../data/benchmarking/{settings[0][0]}.h5ad')\n",
    "        sec = sc.read_h5ad(f'../../data/benchmarking/{settings[0][1]}.h5ad')\n",
    "\n",
    "        fir.layers['velocity'] = pipeline(fir, pipeline_name)\n",
    "        sec.layers['velocity'] = pipeline(sec, pipeline_name)\n",
    "\n",
    "        fir_sub = fir[fir.obs.cell_annotation==cell]\n",
    "        sec_sub = sec[sec.obs.cell_annotation==cell]\n",
    "        shared_cells = list(set(fir_sub.obs_names).intersection(sec_sub.obs_names))\n",
    "        fir_sub = fir_sub[shared_cells]\n",
    "        sec_sub = sec_sub[shared_cells]\n",
    "\n",
    "        for gene in settings[1]:\n",
    "            proceed = True\n",
    "#             try:\n",
    "            firvel = np.array(fir_sub[:,gene].layers['velocity']).flatten()\n",
    "#             except:\n",
    "#                 print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][0]}!\")\n",
    "#                 proceed = False\n",
    "#             try:\n",
    "            secvel = np.array(sec_sub[:,gene].layers['velocity']).flatten()\n",
    "#             except:\n",
    "#                 print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][1]}!\")\n",
    "#                 proceed = False\n",
    "            if proceed:\n",
    "                print('score: ', np.corrcoef(firvel, secvel)[0,1])\n",
    "                scores.append(np.corrcoef(firvel, secvel)[0,1])\n",
    "\n",
    "    scores = np.nan_to_num(scores)\n",
    "    np.save(f'{output_folder}/{pipeline_name}_consistency_scores.npy', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d5d2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'scvelo'\n",
    "pipeline = scvelo_pipeline\n",
    "data = 'splicing'\n",
    "\n",
    "if data == 'splicing':\n",
    "    genes_func = gene_specific_benchmark_splicing\n",
    "    csist_func = consistency_benchmark_splicing\n",
    "elif data == 'labelling':\n",
    "    genes_func = gene_specific_benchmark\n",
    "    csist_func = consistency_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d3e6956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSISTENCY: Neural\n",
      "computing neighbors\n",
      "    finished (0:00:03) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:01) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:03) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing neighbors\n",
      "    finished (0:00:04) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:02) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:06) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "score:  0.5715172423553837\n",
      "score:  0.4456480165395385\n",
      "score:  0.7991163601734586\n",
      "score:  nan\n",
      "CONSISTENCY: pMN\n",
      "computing neighbors\n",
      "    finished (0:00:01) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:00) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:01) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing neighbors\n",
      "    finished (0:00:04) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:02) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:05) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "score:  0.5274698716014153\n",
      "score:  0.6526130573549485\n",
      "score:  0.5472597986406356\n",
      "score:  0.676199994161307\n",
      "CONSISTENCY: MN\n",
      "computing neighbors\n",
      "    finished (0:00:01) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:00) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:01) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing neighbors\n",
      "    finished (0:00:04) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:02) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:06) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "score:  nan\n",
      "score:  0.6950428583689624\n",
      "score:  0.8181249537881724\n",
      "score:  0.695891907798551\n",
      "CONSISTENCY: V3\n",
      "computing neighbors\n",
      "    finished (0:00:01) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:00) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:01) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing neighbors\n",
      "    finished (0:00:04) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:02) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:06) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "score:  nan\n",
      "score:  0.7205207012705408\n",
      "score:  0.9492371305268829\n",
      "score:  0.840115872155599\n",
      "CONSISTENCY: p3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcsist_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../output_data/benchmarking_scores\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPIPELINE_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_CON\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 44\u001b[0m, in \u001b[0;36mconsistency_benchmark_splicing\u001b[0;34m(output_folder, pipeline, pipeline_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONSISTENCY: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m fir \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mread_h5ad(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/benchmarking/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msettings[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5ad\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m sec \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/benchmarking/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5ad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m fir\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvelocity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pipeline(fir, pipeline_name)\n\u001b[1;32m     47\u001b[0m sec\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvelocity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pipeline(sec, pipeline_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anndata/_io/h5ad.py:238\u001b[0m, in \u001b[0;36mread_h5ad\u001b[0;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[1;32m    236\u001b[0m         d[k] \u001b[38;5;241m=\u001b[39m read_dataframe(f[k])\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Base case\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m         d[k] \u001b[38;5;241m=\u001b[39m \u001b[43mread_elem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _read_raw(f, as_sparse, rdasp)\n\u001b[1;32m    242\u001b[0m X_dset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anndata/_io/specs/registry.py:183\u001b[0m, in \u001b[0;36mread_elem\u001b[0;34m(elem, modifiers)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_elem\u001b[39m(\n\u001b[1;32m    179\u001b[0m     elem: Union[H5Array, H5Group, ZarrGroup, ZarrArray],\n\u001b[1;32m    180\u001b[0m     modifiers: \u001b[38;5;28mfrozenset\u001b[39m(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(),\n\u001b[1;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read an element from an on disk store.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_REGISTRY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfrozenset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodifiers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anndata/_io/specs/methods.py:475\u001b[0m, in \u001b[0;36mread_sparse\u001b[0;34m(elem)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;129m@_REGISTRY\u001b[39m\u001b[38;5;241m.\u001b[39mregister_read(H5Group, IOSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    471\u001b[0m \u001b[38;5;129m@_REGISTRY\u001b[39m\u001b[38;5;241m.\u001b[39mregister_read(H5Group, IOSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    472\u001b[0m \u001b[38;5;129m@_REGISTRY\u001b[39m\u001b[38;5;241m.\u001b[39mregister_read(ZarrGroup, IOSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    473\u001b[0m \u001b[38;5;129m@_REGISTRY\u001b[39m\u001b[38;5;241m.\u001b[39mregister_read(ZarrGroup, IOSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_sparse\u001b[39m(elem):\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSparseDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anndata/_core/sparse_dataset.py:379\u001b[0m, in \u001b[0;36mSparseDataset.to_memory\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m format_class \u001b[38;5;241m=\u001b[39m get_memory_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_str)\n\u001b[1;32m    378\u001b[0m mtx \u001b[38;5;241m=\u001b[39m format_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 379\u001b[0m mtx\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    380\u001b[0m mtx\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    381\u001b[0m mtx\u001b[38;5;241m.\u001b[39mindptr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindptr\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/dataset.py:768\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = csist_func(\n",
    "    output_folder='../../output_data/benchmarking_scores', \n",
    "    pipeline=pipeline, \n",
    "    pipeline_name=f'{PIPELINE_NAME}_CON'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "050512da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 34])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num([1,2,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency_benchmark(output_folder, pipeline, pipeline_name):\n",
    "    consistency_results = {\n",
    "        'Neural':[\n",
    "            ['midi_NM','midi_Ne'],\n",
    "            ['Olig2','Irx3','Sema3e','Nkx1-2']\n",
    "        ],\n",
    "        'pMN':[\n",
    "            ['mini_MN','midi_Ne'],\n",
    "            ['Olig2','Neurog2','Mnx1','Isl2']\n",
    "        ],\n",
    "        'MN':[\n",
    "            ['mini_MN','midi_Ne'],\n",
    "            ['Tubb3','Neurog2','Map2','Olig2']\n",
    "        ],\n",
    "        'V3':[\n",
    "            ['mini_V3','midi_Ne'],\n",
    "            ['Tubb3','Sim1','Map2','Stmn2']\n",
    "        ],\n",
    "        'p3':[\n",
    "            ['mini_V3','midi_Ne'],\n",
    "            ['Sim1','Nfia','Sox9','Nfib']\n",
    "        ],\n",
    "        'Mesoderm':[\n",
    "            ['mini_MD','midi_NM'],\n",
    "            ['Meox1','T','Rspo3','Cyp26a1']\n",
    "        ],\n",
    "        'NMP':[\n",
    "            ['midi_NM','maxi'],\n",
    "            ['Rspo3','T','Sema3e','Fgf8']\n",
    "        ],\n",
    "        'FP':[\n",
    "            ['midi_Ne','maxi'],\n",
    "            ['Shh','Arx','Olig2','Foxa2']\n",
    "        ],\n",
    "        'Early_Neural':[\n",
    "            ['midi_NM','maxi'],\n",
    "            ['Nkx1-2','Irx3','Sema3e','Olig2']\n",
    "        ]\n",
    "    }\n",
    "    scores = []\n",
    "    for cell, settings in consistency_results.items():\n",
    "        print(f\"CONSISTENCY: {cell}\")\n",
    "        fir = sc.read_h5ad(f'../../data/benchmarking/{settings[0][0]}.h5ad')\n",
    "        sec = sc.read_h5ad(f'../../data/benchmarking/{settings[0][1]}.h5ad')\n",
    "\n",
    "        fir.layers['velocity'] = pipeline(fir, pipeline_name)\n",
    "        sec.layers['velocity'] = pipeline(sec, pipeline_name)\n",
    "\n",
    "        fir_sub = fir[fir.obs.cell_annotation==cell]\n",
    "        sec_sub = sec[sec.obs.cell_annotation==cell]\n",
    "        shared_cells = list(set(fir_sub.obs_names).intersection(sec_sub.obs_names))\n",
    "        fir_sub = fir_sub[shared_cells]\n",
    "        sec_sub = sec_sub[shared_cells]\n",
    "\n",
    "        for gene in settings[1]:\n",
    "            proceed = True\n",
    "            try:\n",
    "                firvel = np.array(fir_sub[:,gene].layers['velocity']).flatten()\n",
    "            except:\n",
    "                print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][0]}!\")\n",
    "                proceed = False\n",
    "            try:\n",
    "                secvel = np.array(sec_sub[:,gene].layers['velocity']).flatten()\n",
    "            except:\n",
    "                print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][1]}!\")\n",
    "                proceed = False\n",
    "            if proceed:\n",
    "                scores.append(np.corrcoef(firvel, secvel)[0,1])\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    np.save(f'{output_folder}/{pipeline_name}_consistency_scores.npy', scores)\n",
    "    \n",
    "def consistency_benchmark_splicing(output_folder, pipeline, pipeline_name):\n",
    "    consistency_results = {\n",
    "        'Neural':[\n",
    "            ['splicing_midi_NM','splicing_midi_Ne'],\n",
    "            ['Olig2','Irx3','Sema3e','Nkx1-2']\n",
    "        ],\n",
    "        'pMN':[\n",
    "            ['splicing_mini_MN','splicing_midi_Ne'],\n",
    "            ['Olig2','Neurog2','Mnx1','Isl2']\n",
    "        ],\n",
    "        'MN':[\n",
    "            ['splicing_mini_MN','splicing_midi_Ne'],\n",
    "            ['Tubb3','Neurog2','Map2','Olig2']\n",
    "        ],\n",
    "        'V3':[\n",
    "            ['splicing_mini_V3','splicing_midi_Ne'],\n",
    "            ['Tubb3','Sim1','Map2','Stmn2']\n",
    "        ],\n",
    "        'p3':[\n",
    "            ['splicing_mini_V3','splicing_midi_Ne'],\n",
    "            ['Sim1','Nfia','Sox9','Nfib']\n",
    "        ],\n",
    "        'Mesoderm':[\n",
    "            ['splicing_mini_MD','splicing_midi_NM'],\n",
    "            ['Meox1','T','Rspo3','Cyp26a1']\n",
    "        ],\n",
    "        'NMP':[\n",
    "            ['splicing_midi_NM','splicing_maxi'],\n",
    "            ['Rspo3','T','Sema3e','Fgf8']\n",
    "        ],\n",
    "        'FP':[\n",
    "            ['splicing_midi_Ne','splicing_maxi'],\n",
    "            ['Shh','Arx','Olig2','Foxa2']\n",
    "        ],\n",
    "        'Early_Neural':[\n",
    "            ['splicing_midi_NM','splicing_maxi'],\n",
    "            ['Nkx1-2','Irx3','Sema3e','Olig2']\n",
    "        ]\n",
    "    }\n",
    "    scores = []\n",
    "    for cell, settings in consistency_results.items():\n",
    "        print(f\"CONSISTENCY: {cell}\")\n",
    "        fir = sc.read_h5ad(f'../../data/benchmarking/{settings[0][0]}.h5ad')\n",
    "        sec = sc.read_h5ad(f'../../data/benchmarking/{settings[0][1]}.h5ad')\n",
    "\n",
    "        fir.layers['velocity'] = pipeline(fir, pipeline_name)\n",
    "        sec.layers['velocity'] = pipeline(sec, pipeline_name)\n",
    "\n",
    "        fir_sub = fir[fir.obs.cell_annotation==cell]\n",
    "        sec_sub = sec[sec.obs.cell_annotation==cell]\n",
    "        shared_cells = list(set(fir_sub.obs_names).intersection(sec_sub.obs_names))\n",
    "        fir_sub = fir_sub[shared_cells]\n",
    "        sec_sub = sec_sub[shared_cells]\n",
    "\n",
    "        for gene in settings[1]:\n",
    "            proceed = True\n",
    "            try:\n",
    "                firvel = np.array(fir_sub[:,gene].layers['velocity']).flatten()\n",
    "            except:\n",
    "                print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][0]}!\")\n",
    "                proceed = False\n",
    "            try:\n",
    "                secvel = np.array(sec_sub[:,gene].layers['velocity']).flatten()\n",
    "            except:\n",
    "                print(f\"KEY ERROR NOTE: {gene} not found in {settings[0][1]}!\")\n",
    "                proceed = False\n",
    "            if proceed:\n",
    "                scores.append(np.corrcoef(firvel, secvel)[0,1])\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    np.save(f'{output_folder}/{pipeline_name}_consistency_scores.npy', scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velvet_env1",
   "language": "python",
   "name": "velvet_env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
