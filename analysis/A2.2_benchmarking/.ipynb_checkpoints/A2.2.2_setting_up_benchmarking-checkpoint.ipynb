{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536e85cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/camp/home/maizelr/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import velvet as vt\n",
    "\n",
    "# general packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# velocity packages\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import anndata as ann\n",
    "\n",
    "# plotting packages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# color palette object\n",
    "from colors import colorpalette as colpal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7f2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we implement unitvelo's evaluation \n",
    "# originally from https://github.com/StatBiomed/UniTVelo/blob/main/unitvelo/eval_utils.py\n",
    "# paper: https://www.nature.com/articles/s41467-022-34188-7\n",
    "# authors: Mingze Gao, Chen Qiao & Yuanhua Huang \n",
    "\n",
    "from eval_functions import unitvelo_cross_boundary_correctness as cross_boundary_correctness\n",
    "from  eval_functions import unitvelo_inner_cluster_coh as inner_cluster_coh\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bdb3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def velvet_pipeline(adata0, name):\n",
    "    adata = adata0.copy()\n",
    "\n",
    "    adata.layers['total'] = (\n",
    "        adata.layers['total'].A if issparse(adata.layers['total']) else adata.layers['total']\n",
    "    )\n",
    "    adata.layers['new'] = (\n",
    "        adata.layers['new'].A if issparse(adata.layers['new']) else adata.layers['new']\n",
    "    )\n",
    "    \n",
    "    vt.pp.neighborhood(adata, n_neighbors=100)\n",
    "    \n",
    "    vt.ut.set_seed(0)\n",
    "    \n",
    "    vt.md.Velvet.setup_anndata(adata, x_layer='total', n_layer='new', knn_layer='knn_index')\n",
    "\n",
    "    model = vt.md.Velvet(\n",
    "        adata,\n",
    "        n_latent = 50,\n",
    "        linear_decoder = True,\n",
    "        neighborhood_space=\"latent_space\",\n",
    "        biophysical_model = \"full\",\n",
    "        gamma_mode = \"learned\",\n",
    "        labelling_time = 2.0,\n",
    "    )\n",
    "\n",
    "    model.setup_model()\n",
    "    \n",
    "    model.train(\n",
    "        batch_size = adata.shape[0],\n",
    "        max_epochs = 1000, \n",
    "        freeze_vae_after_epochs = 200,\n",
    "        constrain_vf_after_epochs = 200,\n",
    "        lr=0.001,\n",
    "    )\n",
    "    \n",
    "    V = model.predict_velocity()\n",
    "    V = V.A if issparse(V) else V\n",
    "    V = np.nan_to_num(V, nan=0, neginf=0, posinf=0)\n",
    "    \n",
    "    return V\n",
    "\n",
    "def velvet_pipeline_with_smoothing(adata0, name):\n",
    "    adata = adata0.copy()\n",
    "    \n",
    "    adata.layers['total'] = (\n",
    "        adata.layers['total'].A if issparse(adata.layers['total']) else adata.layers['total']\n",
    "    )\n",
    "    adata.layers['new'] = (\n",
    "        adata.layers['new'].A if issparse(adata.layers['new']) else adata.layers['new']\n",
    "    )\n",
    "    \n",
    "    smoothing_cnx = vt.pp.connectivities(adata, n_neighbors=30)\n",
    "\n",
    "    adata.layers['total_smooth'] = vt.pp.moments(X=adata.layers['total'],\n",
    "        cnx=smoothing_cnx\n",
    "    )\n",
    "\n",
    "    adata.layers['new_smooth'] = vt.pp.moments(\n",
    "        X=adata.layers['new'],\n",
    "        cnx=smoothing_cnx\n",
    "    )\n",
    "\n",
    "    vt.pp.neighborhood(adata, n_neighbors=100)\n",
    "\n",
    "    vt.ut.set_seed(0)\n",
    "    \n",
    "    vt.md.Velvet.setup_anndata(adata, x_layer='total_smooth', n_layer='new_smooth', knn_layer='knn_index')\n",
    "\n",
    "    model = vt.md.Velvet(\n",
    "        adata,\n",
    "        n_latent = 50,\n",
    "        linear_decoder = True,\n",
    "        neighborhood_space=\"latent_space\",\n",
    "        biophysical_model = \"full\",\n",
    "        gamma_mode = \"learned\",\n",
    "        labelling_time = 2.0,\n",
    "    )\n",
    "\n",
    "    model.setup_model()\n",
    "    \n",
    "    model.train(\n",
    "        batch_size = adata.shape[0],\n",
    "        max_epochs = 1000, \n",
    "        freeze_vae_after_epochs = 200,\n",
    "        constrain_vf_after_epochs = 200,\n",
    "        lr=0.001,\n",
    "    )\n",
    "    \n",
    "    V = model.predict_velocity()\n",
    "    V = V.A if issparse(V) else V\n",
    "    V = np.nan_to_num(V, nan=0, neginf=0, posinf=0)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27b6105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the object that will contain the data and data-specific parameters for benchmarking\n",
    "\n",
    "class BenchMarkingData:\n",
    "    def __init__(self, name, func, pt=True, scifate2=True):\n",
    "        self.name = name\n",
    "        adata = sc.read_h5ad(f'../../data/benchmarking/{name}.h5ad')\n",
    "        \n",
    "        self.adata = prepare_for_test(\n",
    "            adata,\n",
    "            name,\n",
    "            func,\n",
    "            pt=pt,\n",
    "            scifate2=scifate2\n",
    "        )\n",
    "        \n",
    "        self.cluster_edges()\n",
    "        \n",
    "    def cluster_edges(self):\n",
    "        if self.name == \"mini_MN\":\n",
    "            self.obs = 'leiden'\n",
    "            self.cluster_edges = [\n",
    "                ('0','2'),\n",
    "                ('2','4'),\n",
    "                ('2','3'),\n",
    "                ('4','5'),\n",
    "            ]\n",
    "        elif self.name == \"mini_V3\":\n",
    "            self.obs = 'leiden'\n",
    "            self.cluster_edges = [\n",
    "                ('0','1'),\n",
    "                ('1','3'),\n",
    "                ('3','2'),\n",
    "                ('2','4')\n",
    "            ]\n",
    "        elif self.name == \"mini_MD\":\n",
    "            self.obs = 'leiden'\n",
    "            self.cluster_edges = [\n",
    "                ('2','3'),\n",
    "                ('3','0'),\n",
    "                ('3','5'),\n",
    "                ('0','1'),\n",
    "                ('1','4'),\n",
    "            ]\n",
    "        elif self.name == \"midi_NM\":\n",
    "            self.obs = 'cell_annotation'\n",
    "            self.cluster_edges = [\n",
    "                ('Early_Neural','Neural'),\n",
    "                ('NMP','Early_Neural'),\n",
    "                ('NMP','Mesoderm')\n",
    "            ]\n",
    "        elif self.name == 'midi_Ne':\n",
    "            self.obs = 'cell_annotation'\n",
    "            self.cluster_edges = [\n",
    "                ('Neural','pMN'),\n",
    "                ('pMN','MN'),\n",
    "                ('pMN','p3'),\n",
    "                ('p3','V3')\n",
    "            ]\n",
    "        elif self.name == 'maxi':\n",
    "            self.obs = 'cell_annotation'\n",
    "            self.cluster_edges = [\n",
    "                ('Early_Neural','Neural'),\n",
    "                ('NMP','Early_Neural'),\n",
    "                ('NMP','Mesoderm'),\n",
    "                ('Neural','pMN'),\n",
    "                ('pMN','MN'),\n",
    "                ('pMN','p3'),\n",
    "                ('p3','V3')\n",
    "            ]\n",
    "            \n",
    "        elif self.name == \"dentategyrus_lamanno\":\n",
    "            self.obs = 'clusters'\n",
    "            self.cluster_edges = [\n",
    "                ('Nbl1','Nbl2'),\n",
    "                ('Nbl2','ImmGranule1'),\n",
    "                ('Nbl2','CA'),\n",
    "                ('CA','CA2-3-4'),\n",
    "                ('ImmGranule1','ImmGranule2'),\n",
    "                ('ImmGranule2','Granule')\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"dentategyrus\":\n",
    "            self.obs = 'clusters'\n",
    "            self.cluster_edges = [\n",
    "                ('Neuroblast','Granule immature'),\n",
    "                ('Neuroblast','Granule mature')\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"forebrain\":\n",
    "            self.obs = 'clusters'\n",
    "            self.cluster_edges = [\n",
    "                ('0','1'),\n",
    "                ('1','2'),\n",
    "                ('2','3'),\n",
    "                ('3','4'),\n",
    "                ('4','5'),\n",
    "                ('5','6')\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"gastrulation_erythroid\":\n",
    "            self.obs = 'celltype'\n",
    "            self.cluster_edges = [\n",
    "                ('Blood progenitors 1','Blood progenitors 2'),\n",
    "                ('Blood progenitors 2','Erythroid1'),\n",
    "                ('Erythroid1','Erythroid2'),\n",
    "                ('Erythroid2','Erythroid3'),\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"mouse_motor_neuron\":\n",
    "            self.obs = 'leiden'\n",
    "            self.cluster_edges = [\n",
    "                ('3','2'),\n",
    "                ('4','0'),\n",
    "                ('0','1'),\n",
    "                ('1','5')\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"pancreas\":\n",
    "            self.obs = 'clusters_coarse'\n",
    "            self.cluster_edges = [\n",
    "                ('Ductal','Ngn3 low EP'),\n",
    "                ('Ngn3 low EP','Ngn3 high EP'),\n",
    "                ('Ngn3 high EP','Pre-endocrine'),\n",
    "                ('Pre-endocrine','Endocrine')\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"scifate_processed\":\n",
    "            self.obs = 'treatment_time'\n",
    "            self.cluster_edges = [\n",
    "                ('0h','2h'),\n",
    "                ('2h','4h'),\n",
    "                ('4h','6h'),\n",
    "                ('6h','8h'),\n",
    "                ('8h','10h')\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"wt_data_processed\":\n",
    "            self.obs = 'timepoint'\n",
    "            self.cluster_edges = [\n",
    "                ('0','1'),\n",
    "                ('1','2'),\n",
    "                ('2','3'),\n",
    "            ]\n",
    "\n",
    "        elif self.name == \"scnt_data_processed\":\n",
    "            self.obs = 'KCl_time'\n",
    "            self.cluster_edges = [\n",
    "                (0,15),\n",
    "                (15,30),\n",
    "                (30,60),\n",
    "                (60,120),\n",
    "            ]\n",
    "\n",
    "## functions used in preparing data for benchmarking\n",
    "\n",
    "def project_to_pca(adata):\n",
    "    X = adata.layers['total']\n",
    "    V = adata.layers['velocity']\n",
    "\n",
    "    X = np.array(X.A if issparse(X) else X)\n",
    "    V = np.array(V.A if issparse(V) else V)\n",
    "    V = np.nan_to_num(V, nan=0, neginf=0, posinf=0)\n",
    "    Y = np.clip(X + V, 0, 1000)\n",
    "\n",
    "\n",
    "    Xlog = np.log1p(X)\n",
    "    pca = PCA()\n",
    "    Xpca = pca.fit_transform(Xlog)\n",
    "\n",
    "    Ylog = np.log1p(Y)\n",
    "    Ypca = pca.transform(Ylog)\n",
    "    V = Ypca - Xpca\n",
    "    return V\n",
    "\n",
    "def prepare_for_test(\n",
    "    adata,\n",
    "    name,\n",
    "    func,\n",
    "    ndims=50,\n",
    "    pt=True,\n",
    "    scifate2=True\n",
    "):\n",
    "    if scifate2:\n",
    "        x_pca = adata.obsm['X_pca']\n",
    "        velocity = func(adata, name)\n",
    "\n",
    "        test = ann.AnnData(X=adata.X, obs=adata.obs, var=adata.var,\n",
    "                           layers={'total':adata.layers['total'],\n",
    "                                   'velocity':velocity})\n",
    "\n",
    "        test.obsm['X_pca'] = x_pca[:,:ndims]\n",
    "        test.obsm['cellrank_baseline'] = adata.obsm['velocity_cr_pca'][:,:ndims]\n",
    "        if pt:\n",
    "            test.obsm['pseudotime_baseline'] = adata.obsm['velocity_pst'][:,:ndims]\n",
    "        else:\n",
    "            ## this is a lazy implementation, will create meaningless comparison\n",
    "            ## but it will never get saved\n",
    "            ## this is just for the maxi dataset that we don't have a good\n",
    "            ## pseudotime trajectory skeleton for.\n",
    "            test.obsm['pseudotime_baseline'] = np.zeros_like(test.obsm['cellrank_baseline'])\n",
    "\n",
    "        test.obsm['velocity_pca'] = project_to_pca(test)[:,:ndims]\n",
    "\n",
    "        scv.pp.neighbors(test)\n",
    "    else:\n",
    "        x_pca = adata.obsm['X_pca']\n",
    "        velocity = func(adata, name)\n",
    "\n",
    "        test = ann.AnnData(X=adata.X, obs=adata.obs, var=adata.var,\n",
    "                           layers={'total':adata.layers['total'],\n",
    "                                   'velocity':velocity})\n",
    "\n",
    "        test.obsm['X_pca'] = x_pca[:,:ndims]\n",
    "        test.obsm['velocity_pca'] = project_to_pca(test)[:,:ndims]\n",
    "        \n",
    "        scv.pp.neighbors(test)    \n",
    "        \n",
    "        return test\n",
    "\n",
    "def baseline_scores(\n",
    "    adata\n",
    "):\n",
    "    X = adata.obsm['velocity_pca']\n",
    "    Y1 = adata.obsm['cellrank_baseline']\n",
    "    Y2 = adata.obsm['pseudotime_baseline']\n",
    "    cr_scores = np.diagonal(cosine_similarity(X, Y1))\n",
    "    pt_scores = np.diagonal(cosine_similarity(X, Y2))\n",
    "    return cr_scores, pt_scores\n",
    "\n",
    "def run_tests(bm):\n",
    "    cbd = cross_boundary_correctness(\n",
    "        bm.adata,\n",
    "        k_cluster=bm.obs,\n",
    "        k_velocity='velocity',\n",
    "        x_emb='X_pca',\n",
    "        cluster_edges=bm.cluster_edges\n",
    "    )[1]\n",
    "\n",
    "    icc = inner_cluster_coh(\n",
    "        bm.adata,\n",
    "        k_cluster=bm.obs,\n",
    "        k_velocity='velocity',\n",
    "    )[1]\n",
    "    \n",
    "    crs, pts = baseline_scores(bm.adata)\n",
    "    \n",
    "    return cbd, icc, crs, pts\n",
    "\n",
    "def run_cbd_test_only(bm):\n",
    "    cbd = cross_boundary_correctness(\n",
    "        bm.adata,\n",
    "        k_cluster=bm.obs,\n",
    "        k_velocity='velocity',\n",
    "        x_emb='X_pca',\n",
    "        cluster_edges=bm.cluster_edges\n",
    "    )[1]\n",
    "    \n",
    "    return cbd\n",
    "\n",
    "def perform_benchmark(\n",
    "    pipeline_name,\n",
    "    velocity_pipeline, \n",
    "    output_folder\n",
    "):\n",
    "    dataset = ['mini_V3', 'mini_MN', 'mini_MD',\n",
    "               'midi_NM', 'midi_Ne', 'maxi']\n",
    "    \n",
    "    for ds in tqdm(dataset):  \n",
    "        bm_data = BenchMarkingData(ds, velocity_pipeline, pt=(ds!='maxi'))\n",
    "        print(ds)\n",
    "        cbd, icc, crs, pts = run_tests(bm_data)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CBD.npy', cbd)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_ICC.npy', icc)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CRS.npy', crs)\n",
    "        if ds!='maxi':\n",
    "            np.save(f'{output_folder}/{ds}_{pipeline_name}_PTS.npy', pts)\n",
    "\n",
    "\n",
    "def perform_benchmark_splicing(\n",
    "    pipeline_name,\n",
    "    velocity_pipeline, \n",
    "    output_folder\n",
    "):\n",
    "    dataset = ['splicing_mini_V3', 'splicing_mini_MN', 'splicing_mini_MD',\n",
    "               'splicing_midi_NM', 'splicing_midi_Ne', 'splicing_maxi']\n",
    "\n",
    "    \n",
    "    for ds in tqdm(dataset):  \n",
    "        bm_data = BenchMarkingData(ds, velocity_pipeline, pt=(ds!='splicing_maxi'))\n",
    "        print(ds)\n",
    "        cbd, icc, crs, pts = run_tests(bm_data)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CBD.npy', cbd)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_ICC.npy', icc)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CRS.npy', crs)\n",
    "        if ds!='splicing_maxi':\n",
    "            np.save(f'{output_folder}/{ds}_{pipeline_name}_PTS.npy', pts)\n",
    "            \n",
    "def perform_benchmark_other_labelling(\n",
    "    pipeline_name,\n",
    "    velocity_pipeline,\n",
    "    output_folder,\n",
    "):\n",
    "    dataset = [\n",
    "        'scifate_processed',\n",
    "        'scnt_data_processed',\n",
    "        'wt_data_processed'\n",
    "    ]\n",
    "    \n",
    "    for ds in tqdm(dataset):\n",
    "        bm_data = BenchMarkingData(ds, velocity_pipeline, scifate2=False)\n",
    "        print(ds)\n",
    "        cbd = run_cbd_test_only(bm_data)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CBD.npy', cbd)\n",
    "        \n",
    "def perform_benchmark_other_splicing(\n",
    "    pipeline_name,\n",
    "    velocity_pipeline,\n",
    "    output_folder,\n",
    "):\n",
    "    dataset = [\n",
    "        'pancreas',\n",
    "        'dentategyrus',\n",
    "        'forebrain',\n",
    "        'dentategyrus_lamanno',\n",
    "        'gastrulation_erythroid',\n",
    "        'mouse_motor_neuron'\n",
    "    ]\n",
    "    \n",
    "    for ds in tqdm(dataset):\n",
    "        bm_data = BenchMarkingData(ds, velocity_pipeline, scifate2=False)\n",
    "        print(ds)\n",
    "        cbd = run_cbd_test_only(bm_data)\n",
    "        np.save(f'{output_folder}/{ds}_{pipeline_name}_CBD.npy', cbd)\n",
    "    \n",
    "def gene_specific_benchmark(output_folder, pipeline, pipeline_name):\n",
    "    gene_results = {\n",
    "        'mini_MN':[\n",
    "            ['leiden','4','Olig2','-'],\n",
    "            ['leiden','4','Tubb3','+'],\n",
    "            ['leiden','2','Neurog2','+'],\n",
    "            ['leiden','3','Isl2','+'],\n",
    "        ],\n",
    "        'mini_V3':[\n",
    "            ['leiden','1','Sim1','+'],\n",
    "            ['leiden','1','Sox2','-'],\n",
    "            ['leiden','3','Tubb3','+'],\n",
    "            ['leiden','1','Map2','+'],\n",
    "        ],\n",
    "        'mini_MD':[\n",
    "            ['leiden','3','Sox2','-'],\n",
    "            ['leiden','3','Nkx1-2','-'],\n",
    "            ['leiden','3','T','-'],\n",
    "            ['leiden','2','Meox1','+'],\n",
    "        ],\n",
    "        'midi_NM':[\n",
    "            ['cell_annotation','Neural','Olig2','+'],\n",
    "            ['cell_annotation','Neural','T','-'],\n",
    "            ['cell_annotation','Mesoderm','Meox1','+'],\n",
    "            ['cell_annotation','Early_Neural','Irx3','+'],\n",
    "        ],\n",
    "        'midi_Ne':[\n",
    "            ['cell_annotation','Neural','Olig2','+'],\n",
    "            ['cell_annotation','FP','Shh','+'],\n",
    "            ['cell_annotation','P3','Nkx2-2','+'],\n",
    "            ['cell_annotation','pMN','Irx3','-'],\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for name, settings in gene_results.items():\n",
    "        print(name)\n",
    "        adata = sc.read_h5ad(f'../../data/benchmarking/{name}.h5ad')\n",
    "        adata.layers['velocity'] = pipeline(adata, name)\n",
    "\n",
    "        for seti in settings:\n",
    "            sub = adata[adata.obs[seti[0]]==seti[1]]\n",
    "            vel = sub[:,seti[2]].layers['velocity'].flatten()\n",
    "            if seti[3]=='-':\n",
    "                score = np.mean(vel<0)\n",
    "            elif seti[3]=='+':\n",
    "                score = np.mean(vel>0)\n",
    "            scores.append(score)\n",
    "           \n",
    "    scores = np.array(scores)\n",
    "    np.save(f'{output_folder}/{pipeline_name}_gene_specific_scores.npy', scores)\n",
    "\n",
    "def consistency_benchmark(output_folder, pipeline, pipeline_name):\n",
    "    consistency_results = {\n",
    "        'Neural':[\n",
    "            ['midi_NM','midi_Ne'],\n",
    "            ['Olig2','Irx3','Sema3e','Nkx1-2']\n",
    "        ],\n",
    "        'pMN':[\n",
    "            ['mini_MN','midi_Ne'],\n",
    "            ['Olig2','Neurog2','Mnx1','Isl2']\n",
    "        ],\n",
    "        'MN':[\n",
    "            ['mini_MN','midi_Ne'],\n",
    "            ['Tubb3','Neurog2','Map2','Olig2']\n",
    "        ],\n",
    "        'V3':[\n",
    "            ['mini_V3','midi_Ne'],\n",
    "            ['Tubb3','Sim1','Map2','Stmn2']\n",
    "        ],\n",
    "        'p3':[\n",
    "            ['mini_V3','midi_Ne'],\n",
    "            ['Sim1','Nfia','Sox9','Nfib']\n",
    "        ],\n",
    "        'Mesoderm':[\n",
    "            ['mini_MD','midi_NM'],\n",
    "            ['Meox1','T','Rspo3','Cyp26a1']\n",
    "        ],\n",
    "        'NMP':[\n",
    "            ['midi_NM','maxi'],\n",
    "            ['Rspo3','T','Sema3e','Fgf8']\n",
    "        ],\n",
    "        'FP':[\n",
    "            ['midi_Ne','maxi'],\n",
    "            ['Shh','Arx','Olig2','Foxa2']\n",
    "        ],\n",
    "        'Early_Neural':[\n",
    "            ['midi_NM','maxi'],\n",
    "            ['Nkx1-2','Irx3','Sema3e','Olig2']\n",
    "        ]\n",
    "    }\n",
    "    scores = []\n",
    "    for cell, settings in consistency_results.items():\n",
    "        print(cell)\n",
    "        fir = sc.read_h5ad(f'../../data/benchmarking/{settings[0][0]}.h5ad')\n",
    "        sec = sc.read_h5ad(f'../../data/benchmarking/{settings[0][1]}.h5ad')\n",
    "\n",
    "#         fir.layers['velocity'] = pipeline(fir, pipeline_name)\n",
    "#         sec.layers['velocity'] = pipeline(sec, pipeline_name)\n",
    "\n",
    "        fir_sub = fir[fir.obs.cell_annotation==cell]\n",
    "        sec_sub = sec[sec.obs.cell_annotation==cell]\n",
    "        shared_cells = list(set(fir_sub.obs_names).intersection(sec_sub.obs_names))\n",
    "        fir_sub = fir_sub[shared_cells]\n",
    "        sec_sub = sec_sub[shared_cells]\n",
    "\n",
    "#         firvel = np.array(fir_sub[:,settings[1][0]].layers['velocity']).flatten()\n",
    "#         secvel = np.array(sec_sub[:,settings[1][0]].layers['velocity']).flatten()\n",
    "\n",
    "        for gene in settings[1]:\n",
    "            firvel = np.array(fir_sub[:,gene].layers['total']).flatten()\n",
    "            secvel = np.array(sec_sub[:,gene].layers['total']).flatten()\n",
    "            scores.append(np.corrcoef(firvel, secvel)[0,1])\n",
    "            \n",
    "#     scores = np.array(scores)\n",
    "#     np.save(f'{output_folder}/{pipeline_name}_consistency_scores.npy', scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9d781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform_benchmark(\n",
    "#     pipeline_name='velvet_RAW',\n",
    "#     velocity_pipeline=velvet_pipeline, \n",
    "#     output_folder='../../output_data/benchmarking_scores'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc5e2ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# perform_second_benchmark(\n",
    "#     pipeline_name='velvet_RAW_OMD',\n",
    "#     velocity_pipeline=velvet_pipeline, \n",
    "#     output_folder='../../output_data/benchmarking_scores',\n",
    "#     splicing=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972746e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_specific_benchmark(\n",
    "#     output_folder='../../output_data/benchmarking_scores', \n",
    "#     pipeline=velvet_pipeline, \n",
    "#     pipeline_name='velvet_RAW_GS'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fcaee5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural\n",
      "pMN\n",
      "MN\n",
      "V3\n",
      "p3\n",
      "Mesoderm\n",
      "NMP\n",
      "FP\n",
      "Early_Neural\n"
     ]
    }
   ],
   "source": [
    "consistency_benchmark(\n",
    "    output_folder='../../output_data/benchmarking_scores', \n",
    "    pipeline=velvet_pipeline, \n",
    "    pipeline_name='velvet_RAW_Con'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d005e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c4ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51539c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velvet_env1",
   "language": "python",
   "name": "velvet_env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
